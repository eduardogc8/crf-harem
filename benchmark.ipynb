{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_train = \"data/harem/coleccoes/CDPrimeiroHAREMprimeiroevento.xml\"\n",
    "#patch_train = \"data/harem/coleccoes/test.xml\"\n",
    "patch_test = \"data/harem/coleccoes/colSegundoHAREM.xml\"\n",
    "#patch_test = \"data/harem/coleccoes/test_output.xml\"\n",
    "\n",
    "patch_out_test = \"data/harem/out.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "import xml.etree.ElementTree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens(in_text):\n",
    "    if in_text is None: return []\n",
    "    return nltk.word_tokenize(in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_end_sentence = ['.', ';', '?', '!']\n",
    "\n",
    "#Documents-> DOC-> EM, ALT->EM, OMITIDO->EM\n",
    "tree = et.parse(patch_train)\n",
    "doc_trees = tree.getroot()\n",
    "\n",
    "sentences = []\n",
    "for doc in doc_trees:\n",
    "    \n",
    "    sentence = []\n",
    "    \n",
    "    text = tokens(doc.text)\n",
    "    entities = []\n",
    "    \n",
    "    for tag in doc:\n",
    "        \n",
    "        for t in text:\n",
    "            if t in char_end_sentence:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "            else:\n",
    "                sentence.append((t, 'O'))\n",
    "        \n",
    "        if tag.tag == 'EM':\n",
    "            t_text = tokens(tag.text)\n",
    "            first = True\n",
    "            for t in t_text:\n",
    "                if first:\n",
    "                    first = False\n",
    "                    sentence.append((t, tag.attrib['CATEG'].split('|')[0]+'-B'))\n",
    "                else:    \n",
    "                    sentence.append((t, tag.attrib['CATEG'].split('|')[0]+'-I'))\n",
    "        \n",
    "        elif tag.tag == 'ALT':\n",
    "            t_text = tokens(tag.text)\n",
    "            for a_tag in tag:\n",
    "                end = False\n",
    "                for t in t_text: \n",
    "                    if t == '|':\n",
    "                        end = True\n",
    "                        break\n",
    "                    else:\n",
    "                        sentence.append((t, 'O'))\n",
    "                if end:\n",
    "                    break\n",
    "                first = True\n",
    "                a_text = tokens(a_tag.text)\n",
    "                for t in a_text:\n",
    "                    if first:\n",
    "                        first = False\n",
    "                        sentence.append((t, a_tag.attrib['CATEG'].split('|')[0]+'-B'))\n",
    "                    else:    \n",
    "                        sentence.append((t, a_tag.attrib['CATEG'].split('|')[0]+'-I'))\n",
    "                t_text = tokens(a_tag.tail)\n",
    "        text = tokens(tag.tail)\n",
    "    if len(sentence) > 0:\n",
    "        sentences.append(sentence)\n",
    "        sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_s = len(sentences)\n",
    "train_sents = sentences[:int(size_s-size_s/5)]\n",
    "test_sents = sentences[int(size_s-size_s/5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 3276 820 4096\n"
     ]
    }
   ],
   "source": [
    "print (size_s, len(train_sents), len(test_sents), len(train_sents) + len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for s in sentences:\n",
    "    for ent in s:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sentences[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.replace(',', '').replace('.', '').isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2features(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 197 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORGANIZACAO-B',\n",
       " 'O',\n",
       " 'ORGANIZACAO-I',\n",
       " 'ABSTRACCAO-B',\n",
       " 'TEMPO-B',\n",
       " 'TEMPO-I',\n",
       " 'LOCAL-B',\n",
       " 'VALOR-B',\n",
       " 'VALOR-I',\n",
       " 'PESSOA-B',\n",
       " 'PESSOA-I',\n",
       " 'LOCAL-I',\n",
       " 'ABSTRACCAO-I',\n",
       " 'ACONTECIMENTO-B',\n",
       " 'ACONTECIMENTO-I',\n",
       " 'OBRA-B',\n",
       " 'OUTRO-B',\n",
       " 'OUTRO-I',\n",
       " 'OBRA-I',\n",
       " 'COISA-B',\n",
       " 'COISA-I',\n",
       " 'OBJECTO-B']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "#labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94532772215966565"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "              O      0.985     0.992     0.988     16079\n",
      "        VALOR-B      0.776     0.725     0.750        91\n",
      "        VALOR-I      0.694     0.883     0.777        77\n",
      "      OBJECTO-B      0.000     0.000     0.000         1\n",
      "         OBRA-B      0.348     0.235     0.281        34\n",
      "         OBRA-I      0.250     0.292     0.269        72\n",
      "   ABSTRACCAO-B      0.489     0.262     0.341        84\n",
      "   ABSTRACCAO-I      0.593     0.308     0.405       104\n",
      "ACONTECIMENTO-B      0.200     0.118     0.148        17\n",
      "ACONTECIMENTO-I      0.323     0.189     0.238        53\n",
      "        TEMPO-B      0.810     0.780     0.795        82\n",
      "        TEMPO-I      0.936     0.846     0.889        52\n",
      "       PESSOA-B      0.550     0.518     0.533       139\n",
      "       PESSOA-I      0.566     0.710     0.630       138\n",
      "        LOCAL-B      0.693     0.574     0.628       263\n",
      "        LOCAL-I      0.520     0.503     0.511       177\n",
      "        COISA-B      0.200     0.083     0.118        12\n",
      "        COISA-I      0.000     0.000     0.000         7\n",
      "  ORGANIZACAO-B      0.442     0.456     0.449       125\n",
      "  ORGANIZACAO-I      0.507     0.589     0.545       175\n",
      "        OUTRO-B      1.000     0.125     0.222         8\n",
      "        OUTRO-I      1.000     0.500     0.667         4\n",
      "\n",
      "    avg / total      0.945     0.948     0.945     17794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_no_space_before = ['.', ';', ':', '?', '!', ',', u'«', u'»']\n",
    "\n",
    "def add_words_out(word, sentenc):\n",
    "    if sentenc is None or len(sentenc) == 0:\n",
    "        sentenc = word\n",
    "    else:\n",
    "        if word in char_no_space_before:\n",
    "            sentenc = sentenc + word\n",
    "        else:\n",
    "            sentenc = sentenc + ' ' + word\n",
    "    return sentenc\n",
    "\n",
    "def join_words_out(words):\n",
    "    ret = ''\n",
    "    for w in words:\n",
    "        if len(ret) == 0:\n",
    "            ret = w\n",
    "        else:\n",
    "            if w in char_no_space_before:\n",
    "                ret = ret+w\n",
    "            else:\n",
    "                ret = ret+' '+w\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sent, model):\n",
    "    ret = sent2features([[x] for x in sent])\n",
    "    #for i in ret:\n",
    "    #    print(i['word.lower()'],)\n",
    "    return model.predict([ret])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'LOCAL-B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"O IRA esteve esta semana na ofensiva, paralisando o aeroporto de Londres e causando prejuízos à temporada turística britânica\"\n",
    "predict(tokens(a), crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_tree = et.parse(patch_test)\n",
    "test_docs = test_tree.getroot()\n",
    "\n",
    "out_tree = et.Element(\"colHAREM\")\n",
    "out_tree.set('versao','CAGE2-SegundoHAREM-4')\n",
    "ids = 1\n",
    "\n",
    "# Pra cada Documento\n",
    "for test_doc in test_docs:\n",
    "    \n",
    "    out_doc = et.SubElement(out_tree, \"DOC\")\n",
    "    out_doc.set('DOCID', test_doc.attrib['DOCID'])\n",
    "    \n",
    "    # Pra cada Parágrafo\n",
    "    for test_p in test_doc:\n",
    "        \n",
    "        out_p = et.SubElement(out_doc, 'P')\n",
    "        \n",
    "        test_text = tokens(test_p.text)\n",
    "        \n",
    "        # Pra cada Token\n",
    "        sentenca = []\n",
    "        out_em = None  # Onde deve ser escrito as não Entidades\n",
    "        for test_t in test_text:\n",
    "            \n",
    "            if test_t in char_end_sentence:\n",
    "                # Fim de sentença - Predict\n",
    "                ret = predict(sentenca, crf)\n",
    "                \n",
    "                #Pra cada posição da sentenca\n",
    "                out_s_text = ''\n",
    "                for i in range(len(sentenca)):\n",
    "                    s_r = ret[i]\n",
    "                    s_t = sentenca[i]\n",
    "                    \n",
    "                    if s_r == 'O':\n",
    "                        # Não é Entidade\n",
    "                        out_s_text = add_words_out(s_t, out_s_text)\n",
    "                    else:\n",
    "                        # É Entidade\n",
    "                        if out_em is None:\n",
    "                            out_p.text = add_words_out(out_s_text, out_p.text)\n",
    "                        else:\n",
    "                            out_em.tail = add_words_out(out_s_text, out_em.tail)\n",
    "                        out_s_text = ''\n",
    "                        \n",
    "                        if '-B' in s_r:\n",
    "                            if out_em is None:\n",
    "                                out_p.text = out_p.text\n",
    "                            else:\n",
    "                                out_em.tail = out_em.tail\n",
    "                            out_em = et.SubElement(out_p, 'EM')\n",
    "                            out_em.set('ID', str(ids))\n",
    "                            out_em.set('CATEG', s_r[:s_r.index('-')])\n",
    "                            ids += 1\n",
    "                        out_em.text = add_words_out(s_t, out_em.text)\n",
    "                            \n",
    "                if len(out_s_text) > 0:\n",
    "                    #Texto pós entidades (ou sem entidade) da sentenca\n",
    "                    if out_em is None:\n",
    "                        out_p.text = add_words_out(out_s_text, out_p.text)\n",
    "                    else:\n",
    "                        out_em.tail = add_words_out(out_s_text, out_em.tail)\n",
    "                # Adicionar end charactere\n",
    "                if out_em is None:\n",
    "                    out_p.text = add_words_out(test_t, out_p.text)\n",
    "                else:\n",
    "                    out_em.tail = add_words_out(test_t, out_em.tail)\n",
    "                sentenca = []\n",
    "                \n",
    "            else:\n",
    "                # Sentença não acabou\n",
    "                sentenca.append(test_t)\n",
    "            \n",
    "        # Sobrou sentenca (ex: parágrafo sem ponto final)\n",
    "        if len(sentenca) > 0:\n",
    "            if out_em is None:\n",
    "                out_p.text = add_words_out(join_words_out(sentenca), out_p.text)\n",
    "            else:\n",
    "                out_em.tail = add_words_out(join_words_out(sentenca), out_em.tail)\n",
    "\n",
    "tree = et.ElementTree(out_tree)\n",
    "tree.write(patch_out_test, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
